## 算法保证了效率。但是他们加剧了不平等

关键词: data lot told cnn grades bias technology systems theyve algorithm schools efficiency inequality promised algorithms worsened

作者: Zamira Rahim

发表日期: 2020-08-23 00:00:00

![](https://cdn.cnn.com/cnnnext/dam/assets/200819131958-06-uk-a-level-exams-super-tease.jpg)

[English](Algorithms%20promised%20efficiency.%20But%20they%27ve%20worsened%20inequality.md)

[原网页](https://edition.cnn.com/2020/08/23/tech/algorithms-bias-inequality-intl-gbr/index.html)

伦敦（CNN商业）菲利普（Philip）指责一种算法，该算法可能会失去他在大学学习法律的资格。

这位18岁的年轻人因担心受到大学的影响而没有透露CNN的姓名，他是英格兰，威尔士和北爱尔兰的300,000多名学生中的一员，这些学生于8月13日醒来，获得了至关重要的A级考试成绩，这是大致相当于美国的高中文凭。

由于大流行，今年夏天这些考试被取消了。取而代之的是，学生分数由一种算法确定，该算法是“直接中心绩效模型”，该模型由政府的考试监管机构选择。该模型利用数据收集来产生等级。随后，由于人们对来自较弱势背景的学生的算法偏见产生了强烈抗议，现在，青少年和专家都呼吁对这种技术进行更严格的审查。

菲利普西伦敦学校的老师预测，他的考试将获得2个A级成绩和一个B级成绩，这很容易确保他在埃克塞特大学学习法律。

学生们于8月14日在伦敦市中心的教育部外面示威。

8月13日，该学生坐在家里试图访问该网站，该网站将确认他是否拥有大学学位。

他告诉CNN：“我在楼上试图加载[网站]，而我的妈妈正在楼下做同样的事情。” “她打开它，大声喊叫。他们拒绝了我。

菲利普补充说：“我感觉不太好。” “是的，我对此很不满。但是我和每个人在一起的情况也差不多。”

该模型授予Philip B级和2 Cs。这个少年并不孤单。在英格兰，将近40％的成绩已从教师预测的成绩降级，在公立学校就读的学生比私立学校的学生受到的打击更大。随后许多人失去了在大学的地位。

随后，Uproar进行了抗议，一些青少年在英国教育部外抗议。学生抗议活动的视频在网上广泛共享，其中包括青少年高呼的视频：“演算法！”

经过几天的负面新闻报道，教育部长加文·威廉姆森（Gavin Williamson）宣布，学生将获得老师预测的成绩，而不是该模型分配的分数。

选择的算法旨在确保公平性，方法是确保2020队列的等级分配遵循前几年的模式，高低分数相同。它利用老师预测的成绩和学生的老师排名来确定成绩。但至关重要的是，它还考虑了学校的历史表现，这使来自较富裕背景的学生受益。

在英格兰，向父母收取费用的私立学校通常只有较小的班级，其成绩很难通过模型进行标准化。因此，该算法对这些人群的教师预测成绩给予了更大的权重，这些人群通常比他们在公立学校被降级的同伴更富有和更白。

牛津大学计算机科学系高级研究员海伦娜·韦伯说：“我们所面临的复杂性之一就是算法有很多公平的方法。”

“您可以看到一个论点，[政府]表示[政府]希​​望获得与去年相似的结果。在全国范围内，这可以说是[公平]。但是它完全错过了对个人公平。

她补充说：“显然，这种算法反映并反映了前几年发生的事情。” “因此，它并没有[反映]学校可能[有所改善]的事实。当然，这对公立学校的影响要比对那些成绩一直较高的私立学校的影响要大。”

18岁的乔什·威克斯（Josh Wicks）是英格兰西部威尔特郡奇彭纳姆的一名学生，他说：“让我生气的是（他们）对待公立学校的方式。”他的分数从2 A *和A降为3 As。

他告诉美国有线电视新闻网：“算法认为，如果学校以前没有达到[高分]，[学生]现在就无法获得。” “我只是认为这是光顾的。”

政治风暴使鲍里斯·约翰逊（Boris Johnson）政府的部长们争相作出解释，此前对其处理冠状病毒这一流行病提出了严厉批评。 Covid-19在英国杀死了超过41,000人，使其成为欧洲受灾最严重的国家。

为什么有些算法被指控有偏见？

从社交媒体和签证申请系统到面部识别技术和考试评分，当今整个社会的每个地方都使用算法。

这项技术可以解放现金，陷入困境的政府以及追求创新的公司。但是，专家们长期以来一直对算法偏差的存在提出警告，并且随着自动化流程的日益普及，对歧视的指控也越来越多。

Foxglove联合创始人科里·克里斯德（Cori Crider）说：“高水平的事情只是冰山一角，”该组织对所谓的滥用数字技术提出了挑战。 Crider告诉CNN，该算法复制了所用原始数据中发现的偏差。

8月14日，学生们在伦敦市中心的教育部外面抗议时举着标语牌。

但是，克里德警告不要单单将政策问题归咎于这项技术的冲动。

她说：“任何告诉你这是技术问题的人都在说谎。”

“（考试）发生的是，做出了一种政治选择，以最大程度地降低年级通货膨胀。这是一种政治选择，而不是技术选择。”

Foxglove和移民福利联合委员会最近向英国内政部提出挑战，要求其使用旨在流式处理签证申请的算法。激进团体声称该算法对某些国家的申请人有偏见，使这种申请人自动更有可能被拒绝签证。

福克斯洛夫洛夫（Foxglove）声称，筛查系统存在反馈循环，“过去的偏见和歧视被输入计算机程序，加剧了未来的偏见和歧视。”

英国内政部发言人告诉美国有线电视新闻网：“我们一直在审查签证申请流媒体工具的工作方式，并将重新设计流程，以使其更加简化和安全。”

“但我们不接受移民福利联合委员会在司法审查中提出的指控，尽管诉讼仍在进行中，该部门不宜再发表评论。”

克里斯德说，福克斯洛夫洛夫用过去的数据发现的导致偏向算法的问题在其他地方很明显，这表明对美国预测性警务计划的争论。

六月，加利福尼亚州的圣克鲁斯市禁止在有关工作中使用的分析软件程序人员歧视有色人种的担忧的预测性管制。

6月，市长贾斯汀·卡明斯（Justin Cummings）对路透社说：“我们拥有可以针对社区中有色人种的技术-我们不需要这种技术。”

Crider说：“部分问题是要输入数据。”

“历史数据正在馈入[算法]，它们正在复制[现有]偏差。”

韦伯同意。她说：“ ​​[很多问题]都是关于算法从中学习的数据。” “例如，出现了许多面部识别技术……问题是，许多（那些）系统都在许多白人男性脸上接受了训练。

“因此，当使用该软件时，它非常擅长识别白人，但不擅长识别有色人种。这来自数据以及将数据放入算法的方式。”

韦伯补充说，她认为可以通过“更多地关注数据集的包容性”和推动在算法的开发中增加更多的“声音多样性”来部分缓解这些问题。

增加监管？

活动家和专家告诉美国有线电视新闻网，他们希望有关算法的近期辩论将导致对该技术的更大监督。

韦伯说：“缺乏对这些系统使用方式的监管。”他补充说，企业也可以选择自我监管。

一些公司在这个问题上的声音越来越明显。

Instagram首席执行官亚当·莫塞里（Adam Mosseri）在6月发表的关于公司多元化努力的声明中写道：“某些技术可能会重复我们有偏见的社会所形成的模式。” “尽管我们做了很多工作来帮助防止产品中的潜意识偏差，但我们需要更加认真地研究我们所构建的基础系统，以及需要做更多的工作以使偏差避免这些决策。”

拥有Instagram的Facebook随后成立了新团队来审查公司系统中的偏见。

Crider说：“我希望在[算法的使用]上看到民主的反击。” “在公共生活中，有没有地区根本无法拥有这些系统？”

尽管在董事会和学术界仍在争论不休，但这些自动化系统仍在以各种微妙的方式决定人们的生活。

对于菲利普来说，英国政府取消考试算法使他陷入了困境。

他说：“我们给埃克塞特[大学]发了电子邮件，并打了电话，他们陷入了混乱。”他补充说，他希望自己能夺回自己的位置。 “我想无论如何我都会推迟。”

他说，他很感激能获得预期的成绩，但他说，经历“非常糟糕”。

他说：“（政府）有几个月的时间来解决这个问题。” “我知道健康方面有很多事情发生，但是表现却很差劲。”